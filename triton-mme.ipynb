{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to run multiple deep learning models on GPUs with Azure Machine Learning Multi-model endpoints (MME) using Triton Inference Server"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-sdk\n",
        "!pip install azureml-core\n",
        "!pip install azureml-contrib-server[all]==1.14.0\n",
        "!pip install azureml-contrib-triton==1.14.0"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Environment, Model, Webservice\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.compute import AksCompute, ComputeTarget\n",
        "from azureml.contrib.server.dashboard import serve_dashboard\n",
        "from azureml.contrib.server.utils import get_auth_header\n",
        "from azureml.contrib.triton.deploy import deploy_triton, AksInferenceCluster\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Azure Machine Learning workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "aks_compute_name = 'triton-demo-aks-cluster'\n",
        "aks_compute = ComputeTarget(workspace=ws, name=aks_compute_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Triton Inference Server configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "triton_config = {\n",
        "    \"name\": \"ms-reactor-demo-triton-server\",\n",
        "    \"compute\": {\n",
        "        \"resource_group\": ws.resource_group,\n",
        "        \"cluster_name\": aks_compute_name,\n",
        "        \"namespace\": \"my-namespace\",\n",
        "        \"pvc_name\": \"my-pvc-name\",\n",
        "        \"max_concurrent_requests_per_replica\": 4,\n",
        "        \"replicas\": 1,\n",
        "        \"gpus_per_node\": 1,\n",
        "        \"cpu_cores\": 4,\n",
        "        \"memory_gb\": 16\n",
        "    },\n",
        "    \"models\": [{\n",
        "        \"model_name\": \"model-1\",\n",
        "        \"model_path\"    : Model.get_model_path(\"model-1\"),\n",
        "        \"model_type\": \"tensorflow\",\n",
        "        \"input_type\": \"fp32\",\n",
        "        \"output_type\": \"fp32\",\n",
        "        \"max_batch_size\": 16,\n",
        "        \"version\": 1\n",
        "    }, {\n",
        "        \"model_name\": \"model-2\",\n",
        "        \"model_path\": Model.get_model_path(\"model-2\"),\n",
        "        \"model_type\": \"onnx\",\n",
        "        \"input_type\": \"fp32\",\n",
        "        \"output_type\": \"fp32\",\n",
        "        \"max_batch_size\": 8,\n",
        "        \"version\": 1\n",
        "    }]\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Triton Inference Server using Azure Machine Learning Multi-model endpoints (MME)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aks_config = AksInferenceCluster(ws, aks_compute_name)\n",
        "deploy_triton(ws, triton_config, aks_config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up and deploy the Azure Machine Learning Multi-model endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment.from_conda_specification(name=\"myenv\", file_path=\"conda_env.yaml\")\n",
        "models = [\n",
        "    Model(ws, \"model-1\"),\n",
        "    Model(ws, \"model-2\")\n",
        "]\n",
        "mme = Model.deploy(ws, \"my-mme-endpoint\", models, inference_config=None, deployment_config=AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1), environment=env)\n",
        "mme.wait_for_deployment(show_output=True)   "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the deployed endpoint using the Triton Inference Server client "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tritonclient.grpc as grpcclient\n",
        "from tritonclient.utils import InferenceServerException\n",
        "from tritonclient.utils import triton_to_np_dtype\n",
        "\n",
        "def test_endpoint():\n",
        "    try:\n",
        "        triton_client = grpcclient.InferenceServerClient(\"my-triton-server:8001\")\n",
        "        inputs = [\n",
        "            grpcclient.InferInput(\"input_1\", [1, 224, 224, 3], \"FP32\"),\n",
        "            grpcclient"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}